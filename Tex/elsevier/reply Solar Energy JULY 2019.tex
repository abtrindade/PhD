\documentclass[11pt]{article}

\usepackage[normalem]{ulem}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\usepackage{url}
%\usepackage{mathtools}
\usepackage{enumerate}
\usepackage[nodayofweek]{datetime}
\usepackage[caption=false]{subfig}
%\mathtoolsset{showonlyrefs}
\usepackage[linesnumbered,lined,ruled,boxed]{algorithm2e}
\SetKw{KwBy}{by}
\usepackage{xcolor}
%\input{rgbcolors}
%\usepackage{color}
\usepackage{natbib}
% \usepackage[style=authoryear-comp,dashed=false]{biblatex}
% \bibliography{piecewise_lyapunov}
\newtheorem{myassumption}{Assumption}
\newcommand{\mstitle}{Automated Formal Verification of Stand-alone Solar Photovoltaic Systems}
\newcommand{\refnumber}{SE-D-19-01248}
\newenvironment{resposta}{~~~\begin{quote}\color{blue}\textbf{Response:}}{\end{quote}}
\newcommand{\comment}[1]{}
%\definecolor{DarkGreen}{rgb}{0.2, 0.4, 0.2}
\usepackage{amsmath}
\usepackage{listings}
\lstset{language=C,basicstyle=\small\ttfamily}
\usepackage{tikz}
\usetikzlibrary{positioning, automata, shapes.arrows, calc, shapes, arrows, calc,patterns,decorations.pathmorphing,decorations.markings}

\newcommand{\param}[2]{\ensuremath{\langle{#1},{#2}\rangle}\xspace}
\textwidth 15cm
\setlength{\textheight}{1.1\textheight}
\newcommand\hi{\hspace*{\parindent}}
\newcommand\vi{\vspace{\baselineskip}}
\newcommand\lac{{\mbox{{\Huge\bf L}\hspace{-0.65em}
\raisebox{-1.2ex}{\Huge\bf A}\hspace{-1.1em}
\raisebox{-0.6ex}{\Huge\bf C~}}}}
\newcommand{\fwlfunction}[1]{\mathcal{FWL}[#1]}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{Manuscript Reference Number: \refnumber}
\rhead{Page \thepage\ of \pageref{LastPage}}
\lfoot{}
\rfoot{}

%\pagestyle{headings}
\pagenumbering{roman}
\begin{document}
\setcounter{page}{1}
\thispagestyle{empty}


\hoffset -1.5cm \voffset .5cm


\sf

\vspace*{-2.5cm} \hspace*{-0.1cm} {\small
{\mbox{\begin{minipage}{2cm}
\centerline{\includegraphics[width=1.5cm]{ufam_logo.png}}
\end{minipage}}} \hspace*{0.1cm}
\begin{minipage}{11.0cm}{\large \textbf{Federal University of Amazonas}}\\
{\sc Faculty of Technology}\\
{\sc Department of Electricity}
\end{minipage}
} \vspace*{0mm}

\hspace*{-.7cm} {\rule[-1ex]{15cm}{0.03cm}}

\begin{flushright}
\begin{minipage}{7.0cm}\small
{\bf Please Reply to:}\\
Assistant Professor Alessandro Trindade\\
Universidade Federal do Amazonas\\
Departamento de Eletricidade\\
Av. Gal. Rodrigo Otávio, 3000, Japiim, Campus Universitário\\
ZIP 69077-000, Manaus - AM, Brazil\\
{\em alessandrotrindade@ufam.edu.br}
\end{minipage}
\end{flushright}
 
\vi
\hspace*{\fill}{\small Manaus, \today.}
\vi



\begin{flushleft}
    Mario A. Medina, PhD, PE\\
    Associate Editor\\
	Solar Energy
    \end{flushleft}
\vi

\begin{flushleft}
\textbf{REF.:} \refnumber
    \end{flushleft}
\vi \vi
 
\indent Dear Mario,
\vi 

We thank you for asking us to comply with your reviewers' reports. 
We are submitting a revised version of our manuscript entitled 
``{\em \mstitle}'' by Alessandro Trindade and Lucas Cordeiro. 
This revised version carefully addresses each comment provided 
by the reviewers, as suggested in your original decision letter. 
In particular, our reply letter describes all modifications we made 
to our manuscript and the respective responses to the comments 
raised by the reviewers.  

%\vi

%Thank you very much in advance.

\vi\vi

\indent
Sincerely,\\



\begin{quote}
\begin{quote}
\begin{flushright}


\vi
\vi

Alessandro B. Trindade~~~~~~~
\end{flushright}
\end{quote}
\end{quote}

\hoffset -1.5cm \voffset .5cm


% =============================================
\newpage
\subsection*{Authors'  Response to the Review Comments on manuscript ``{\mstitle}'' -- Manuscript Reference Number: \refnumber}

\vi

The authors would like to thank the anonymous reviewers for their valuable and constructive comments and suggestions, which helped us significantly improve the quality of our manuscript. 

According to the associate editor and reviewers' comments, our manuscript has been carefully revised and all detailed changes are highlighted in red color, along with the original text. The revision included the Abstract, Introduction, and Results sections.

Our responses  to all comments (in blue color) are given in the sequel, with clear indications about how and where they were addressed along our manuscript.

We hope those modifications in our manuscript and also our responses are sufficient to make our work suitable for publication in {\bf Solar Energy}.



\newpage
\subsection*{Reviewer \#2 comments followed by the authors' answers:}

\begin{quote}

In the manuscript, the authors report about the first application of software model checking to formally verify the design of a stand-alone solar photovoltaic system including solar panel, charge controller, battery, inverter, and electric load. They show, case studies, from real photovoltaic systems deployed in five different places, ranging from 700 W to 1,200 W, were used to evaluate this proposed approach and to compare that with specialized simulation tools. Also, the authors reported the evaluated different verification tools, in order to compare performance and soundness. Data from practical applications show the effectiveness of their approach, where specific conditions that lead to failures in a photovoltaic solar system are only detailed by the automated verification method.

I have specifics questions and suggestions in order to improvement the manuscript.

1.-To clarify the figure 2, i recommend write "current" inside the figure, don't put just I.

\begin{resposta} 
We thank the kind comment provided by this reviewer. Indeed, it summarizes what was intended to be done with this manuscript. In addition, we should highlight that the main focus was at the validation process of the solar PV system, instead of the mathematical modelling that was investigated in prior studies over the last two decades. This information was carefully included at the revised Abstract, Introduction and at the Conclusion sections, because we concluded that was not clear in the previous version of the paper.

Regarding the Figure 2, we did as highlighted by the reviewer. Moreover, we did the same to voltage V in order to keep the same standard.


\end{resposta}

2.-This software model checking has performance in comparison the other commercials software,how is this performance?, Could you give the areas where your software performs better than commercial software?   

\begin{resposta} 
Here it is worth to mention that our options about specialized off-the-shelf tools were reduced. As informed at Section 2.1 of the paper, only Hybrid2 and HOMER Pro perform off-grid with battery analysis of PV systems. Hybrid2 is not supported anymore, being in disuse. This information was updated to the paper. Therefore, at this particular kind of system (stand-alone solar PV systems), only HOMER Pro could be used for comparative. Nevertheless, some general use simulation could be used, with the same mathematical model adopted by the automated verification tool. Because of that, we included a mention to that issue in the section 5.4 (Threats to Validity).

Model checking and software simulation are two different techniques that uses mathematical models. However how they work is completely different. Simulation depends on the choice of input variables (and their values) in order to obtain the output. In the other hand, model checking performs an automatic output search that causes the system to fails (a not expected behavior of the system) and presents the input that causes it. Therefore with model checking we can prove the absence of system flaws. This information was included at the revised text as well.

Model checking explores more efficiently the design-space because the specification of the system is based on formal notation (that is converted to Boolean algebra) and the evaluation of variables is made automatically based on constraints (basically system information and electrical load demand transformed in software code) and properties (use defined demands, weather variables that the use do not have precise forecasting). This resulting mathematical model pass through a exploration of its possible states in order to find a configuration where occurs or not a fail. Logically, depending on the number of variables, the number of states explode and is time-consuming during computing of the result.

However, the authors showed in 2016\footnote{Trindade, A.B. and Cordeiro, Applying SMT-based verification to hardware/software partitioning in embedded systems. Des Autom Embed Syst (2016) 20: 1. https://doi.org/10.1007/s10617-015-9163-z} that model checking can present better performance than simulation software when performing hardware-software partitioning in specifically amount of instances.

\end{resposta}

3.-In text reference at figure 1 the authors do not describe all symbols drawn into image, for instances, what is means G, T. I suspect that in section 4 they define which are the variables (Irradiation and temperature). I suggest you define those symbols in the text that that figure describes.

\begin{resposta} 
Indeed, we miss this information at paragraph that describes the Figure. We thank you so much for this observation. Therefore we revised the text and described every symbol. The final version of the paragraphs were: "A stand-alone PV system is illustrated in Fig.1. The PV generator is a semiconductor device that can convert solar energy into DC electricity, with high dependence of two weather variables from the site where the system is deployed: solar irradiance $G$ and temperature $T$. For night hours or rainy days, power stored in batteries can be used and it implies the presence of a charge controller. The PV arrays produce DC and therefore when the PV system contains an AC load, a DC/AC conversion is required (inverter). The AC load dictates the behavior of AC electrical load from the house that will be fed by the system. At this pictured modular structure, every element produces/consumes current $I$ and voltage $V$ as illustrated by their physical magnitudes, where $pv$ means photovoltaic, $bat$ is battery, $dc$ is direct and $ac$ is alternating signals.".
\end{resposta}

4.- Are the verification results carried out affected by the different characteristics of the computers?

\begin{resposta} 
Indeed, we did not inform the impact the changing of computer setup or related issues. We thank you so much for this observation. Therefore we revised the text and included the following paragraph: "Note that the results presented here depend on the computer's processor and memory, the version of each tool (CBMC, ESBMC, CPAchecker), the parameters passed by the command-line, and the algorithm to be solved. Additionally, any change from HOMER Pro to another simulation tool can influence the measured time to obtain results.".
\end{resposta}

\end{quote}
\newpage


\subsection*{Reviewer \#4 comments followed by the authors' answers:} 

\begin{quote}

The topic itself is interest for the PV application. However some section including abstract and result must be rewritten to be enhanced, here are the comments: 

-       The manuscript illustrated the main drawback from other existed work that they are based on simulation and the proposed approach is claimed to do evaluation based real PV system as illustrated in the abstract, however the evolution is based on simulation model, mathematical, and information from website data such as Weather base and Energy Plus. The author should present real data measurement for more accurate results then compared and the main difference should be clarified.

\begin{resposta} 
We appreciate the comments and we realized that our text was not clear. As told for the Reviewer \#2, we should highlight that our main focus was at the validation process of the solar PV system, instead of the mathematical modelling that was investigated in prior studies over the last two decades. Moreover, we compare the results of using automated verification with simulation tool; real PV systems were just to check the validation results presented by the two tools. Because the automated verification and simulation tools are intended to be used during the project, before the buying or deployment of equipment. This information was carefully included at the revised Abstract, Introduction and at the Conclusion sections, because we concluded that was not clear in the previous version of the paper.

The authors have real load curve, and information collected from monitoring system of four (in five) PV systems/cases, however based on the fact that the automated verification is mathematical and not visual (curves/plots), seems that is not a adequate way of comparative.

The information from temperature and solar irradiance from every site, used to the simulation and formal verification tools, come from historical data collected from real stations that are available in Weather Base and Energy Plus web sites. Considering that the idea of the work is to show the effectiveness of the proposal just after the design phase, before deployment, seems that is plausible that procedure. Worth to mention that the sites from four case studies (the ones in a riverside indigenous community) do not have weather station available to collect data and the information must be approximated to Manaus data (the closet site with historic data).
\end{resposta}

-       Section 5 "Experimental Evolution" It can be changed to Verification result, otherwise the author should clarify the real measurements of the system.

\begin{resposta} 
We thank the reviewer for this comment. We did as suggested and changed the section title to "Verification and Simulation Results", because the results were related to verification and simulation tools only. The data collected from dwellers with real PV systems were used just to confirm flaws and complains about the equipment deployed at the field. The idea was not to present wave forms because how automated verification works it is different of simulation or testing.
\end{resposta}

-       Can the author present the main waveform of the PV system in the steady state operation and under failure or any environmental change? waveforms such as: Input power, VMPP, IMPP, AC load  

\begin{resposta} 
As explained at the first question, here the authors failed in explain better the study. We appreciate one more time the comment and the opportunity to correct this issue. 

At the paper, we compare model checking with simulation tool. However how they work is completely different. Simulation depends on the choice of input variables (and their values) in order to obtain the output. In the other hand, model checking performs an automatic output search that causes the system to fails (a not expected behavior of the system) and presents the input that causes it. Therefore with model checking we can prove the absence of system flaws.

When we work with waveform we are performing testing of simulation, and that is different of automated verification that is a mathematical prove (of correctness or flaw). Based on the fact that the authors have the five cases deployed at the field, and with monitoring system in four those PV systems, it is possible to add waveforms to the work. However, the use of this resource seems that is not a adequate way of comparative. However, we included details about the estimated load curve of each case study at the revised paper (section 4) that is represented by a vector with 24 elements (one to each hour of the day).
\end{resposta}
\end{quote}

\label{LastPage}

% \printbibliography
\end{document} 
